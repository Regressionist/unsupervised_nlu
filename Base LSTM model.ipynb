{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle as pkl\n",
    "from collections import defaultdict,deque,Counter,OrderedDict\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.p\",\"rb\") as f:\n",
    "    traindict = pkl.load(f)\n",
    "with open(\"val.p\",\"rb\") as f:\n",
    "    valdict = pkl.load(f)\n",
    "with open(\"test.p\",\"rb\") as f:\n",
    "    testdict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tagset.txt') as f:\n",
    "    alltags = f.read()\n",
    "\n",
    "alltags = list(map(lambda strline: strline.split('\\t')[1], alltags.split('\\n')))\n",
    "alltags = set(alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = Counter([word[0] if not word[0].isnumeric() and word[1] in alltags else 'UNK' for word in traindict['tagged_words']])\n",
    "generic_vocab = ['SOS','EOS','PAD']+list([w for w in word_freq if word_freq[w]>5])\n",
    "generic_word2id = {}\n",
    "generic_id2word = {}\n",
    "for i,word in enumerate(generic_vocab):\n",
    "    generic_word2id[word] = i\n",
    "    generic_id2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgebase = defaultdict(deque)\n",
    "for (word,tag) in traindict['tagged_words']:\n",
    "    if tag in alltags:\n",
    "        if word not in knowledgebase[tag]:\n",
    "            if word in word_freq and word_freq[word]>5:\n",
    "                knowledgebase[tag].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in knowledgebase.keys():\n",
    "    knowledgebase[tag].appendleft('UNK')\n",
    "    knowledgebase[tag].appendleft('PAD')\n",
    "    knowledgebase[tag].appendleft('EOS')\n",
    "    knowledgebase[tag].appendleft('SOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = defaultdict(int)\n",
    "id2tag = defaultdict(str)\n",
    "for i, tag in enumerate(alltags):\n",
    "    tag2id[tag] = i\n",
    "    id2tag[i] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBDataset(object):\n",
    "    def __init__(self, instanceDict, word2id):\n",
    "        self.root = instanceDict['tagged_sents']\n",
    "        self.word2id = word2id\n",
    "        self.sents = [[s[0] for s in sentences] for sentences in self.root]\n",
    "        self.sents.sort(key=lambda x:len(x))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.root)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        target_sent = [self.word2id[word] if word in self.word2id else self.word2id['UNK'] for word in self.sents[idx]]\n",
    "        input_sent = [self.word2id['SOS']] + target_sent\n",
    "        target_sent.append(self.word2id['EOS'])\n",
    "        return (torch.as_tensor([input_sent], dtype=torch.long), torch.as_tensor([target_sent], dtype=torch.long))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSDataset(object):\n",
    "    def __init__(self, instanceDict, word2id, tag2id):\n",
    "        self.root = instanceDict['tagged_sents']\n",
    "        self.tag2id = tag2id\n",
    "        self.word2id = word2id\n",
    "        self.root.sort(key=lambda x:len(x))\n",
    "        self.sents = [[s[0] for s in sentences] for sentences in self.root]\n",
    "        self.tags = [[s[1] for s in sentences] for sentences in self.root]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.root)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        target_labels = [self.tag2id[tag] for tag in self.tags[idx]]\n",
    "        target_sent = [self.word2id[word] if word in self.word2id else self.word2id['UNK'] for word in self.sents[idx]]\n",
    "        input_sent = [self.word2id['SOS']]+[self.word2id[word] if word in self.word2id else self.word2id['UNK'] for word in self.sents[idx]]\n",
    "        target_sent.append(self.word2id['EOS'])\n",
    "        return (torch.as_tensor([input_sent], dtype=torch.long), torch.as_tensor([target_sent], dtype=torch.long), torch.as_tensor([target_labels], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PTBDataset(traindict,generic_word2id)\n",
    "val_dataset = POSDataset(valdict,generic_word2id,tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
    "    max_length = max([t.size(-1) for t in list_of_tensors])\n",
    "    padded_list = []\n",
    "    for t in list_of_tensors:\n",
    "        padded_tensor = torch.cat([t, torch.tensor([[pad_token]*(max_length - t.size(-1))], dtype=torch.long)], dim = -1)\n",
    "        padded_list.append(padded_tensor)\n",
    "    padded_tensor = torch.cat(padded_list, dim=0)\n",
    "    return padded_tensor\n",
    "def pad_collate_fn_lm(batch):\n",
    "    # batch is a list of sample tuples\n",
    "    input_list = [s[0] for s in batch]\n",
    "    target_list = [s[1] for s in batch]\n",
    "    pad_token = 2    \n",
    "    input_tensor = pad_list_of_tensors(input_list, pad_token)\n",
    "    target_tensor = pad_list_of_tensors(target_list, pad_token)\n",
    "    return input_tensor, target_tensor\n",
    "def pad_collate_fn_pos(batch):\n",
    "    # batch is a list of sample tuples\n",
    "    input_list = [s[0] for s in batch]\n",
    "    target_list = [s[1] for s in batch]\n",
    "    target_labels = [s[2] for s in batch]\n",
    "    pad_token_input = 2 \n",
    "    pad_token_tags = 37\n",
    "    input_tensor = pad_list_of_tensors(input_list, pad_token_input)\n",
    "    target_tensor = pad_list_of_tensors(target_list, pad_token_input)\n",
    "    target_labels = pad_list_of_tensors(target_labels, pad_token_tags)\n",
    "    return input_tensor, target_tensor, target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38219"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=pad_collate_fn_lm, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=pad_collate_fn_pos,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(nn.Module):\n",
    "    def __init__(self,vocab_size,hidden_size,token_embedding_size,tag_embedding_size,tags,mask,device):\n",
    "\n",
    "        super(LM, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.token_embedding_size = token_embedding_size\n",
    "        self.tag_embedding_size = tag_embedding_size\n",
    "        self.num_tags = len(tags)+1\n",
    "        self.tags = tags\n",
    "        self.mask = mask\n",
    "        self.device=device\n",
    "        \n",
    "        self.token_embedding = nn.Embedding(self.vocab_size,self.token_embedding_size)\n",
    "        self.lstm = nn.LSTM(self.token_embedding_size, self.hidden_size, num_layers = 1, batch_first = True, bias=False)\n",
    "        self.tag_linear = nn.Linear(self.tag_embedding_size,self.num_tags,bias=False)\n",
    "        self.lower_hidden = nn.Linear(self.hidden_size,self.tag_embedding_size,bias=False)\n",
    "        self.tag_projections = nn.ModuleList([nn.Linear(self.hidden_size,self.vocab_size,bias=False) for i in range(self.num_tags)])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,input_seq):\n",
    "        if self.training:\n",
    "            batch_size,sent_len = input_seq.shape[0],input_seq.shape[1]\n",
    "            h = torch.zeros((1,batch_size,self.hidden_size),device=self.device)\n",
    "            c = torch.zeros((1,batch_size,self.hidden_size),device=self.device)\n",
    "            embeddings = self.token_embedding(input_seq) #batch_size, sent_len, embed_size\n",
    "            outputs = torch.zeros((batch_size,sent_len,self.vocab_size),device=device)\n",
    "            for idx in range(sent_len):\n",
    "                embedding_input = embeddings[:,idx,:].view(batch_size,1,self.token_embedding_size)\n",
    "                _,(h,c) = self.lstm(embedding_input,(h,c))\n",
    "                h_lower = self.lower_hidden(h.transpose(0,1).view(batch_size,-1)) #batch_size,100\n",
    "                tag_weights = F.softmax(self.tag_linear(h_lower),dim=-1) #batch_size,num_tags\n",
    "                #word_distributions = torch.cat([(F.softmax((self.tag_projections[i](h.squeeze(0)))*self.mask[i],dim=-1)).unsqueeze(1) for i in range(self.num_tags)],dim=1)#batch_size,num_tags,vocab_size\n",
    "                #print(word_distributions[0][:2])\n",
    "                word_distributions_logits = torch.cat([((self.tag_projections[i](h.squeeze(0)))*self.mask[i]).unsqueeze(1) for i in range(self.num_tags)],dim=1)\n",
    "                word_distributions = F.softmax(word_distributions_logits,dim=-1)\n",
    "#                 print(word_distributions_logits[0][:2])\n",
    "#                 print(torch.max(word_distributions_logits[0][0]))\n",
    "#                 print(word_distributions[0][:2])\n",
    "                attended_words = torch.bmm(tag_weights.unsqueeze(1),word_distributions)\n",
    "                outputs[:,idx,:] = attended_words.squeeze(1)\n",
    "            return torch.log(outputs)\n",
    "        elif self.eval:\n",
    "            with torch.no_grad():\n",
    "                batch_size,sent_len = input_seq.shape[0],input_seq.shape[1]\n",
    "                h = torch.zeros((1,input_seq.shape[0],self.hidden_size),device=self.device)\n",
    "                c = torch.zeros((1,input_seq.shape[0],self.hidden_size),device=self.device)\n",
    "                embeddings = self.token_embedding(input_seq) #batch_size, sent_len, embed_size\n",
    "                pred_tag = torch.zeros((batch_size,sent_len),device=device)\n",
    "                pred_word = torch.zeros((batch_size,sent_len,self.vocab_size),device=device)\n",
    "                for idx in range(sent_len):\n",
    "                    embedding_input = embeddings[:,idx,:].view(batch_size,1,self.token_embedding_size)\n",
    "                    _,(h,c) = self.lstm(embedding_input,(h,c))\n",
    "                    h_lower = self.lower_hidden(h.transpose(0,1).view(batch_size,-1)) #batch_size,100\n",
    "                    tag_weights = F.softmax(self.tag_linear(h_lower),dim=-1) #batch_size,num_tags\n",
    "                    pred_tag[:,idx] = torch.argmax(tag_weights[:,:-1],dim=-1) \n",
    "                    \n",
    "                    word_distributions = torch.cat([(F.softmax((self.tag_projections[i](h.squeeze(0)))*self.mask[i],dim=-1)).unsqueeze(1) for i in range(self.num_tags)],dim=1)#batch_size,tag_vocab_size\n",
    "                    attended_words = torch.bmm(tag_weights.unsqueeze(1),word_distributions)\n",
    "                    pred_word[:,idx,:] = attended_words.squeeze(1)\n",
    "            \n",
    "                return pred_tag,torch.log(pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(generic_vocab)\n",
    "HIDDEN_SIZE = 512\n",
    "EMBEDDING_SIZE = 256\n",
    "TAG_EMBEDDING_SIZE = 128\n",
    "device = torch.device('cuda:2')\n",
    "mask = torch.zeros(len(knowledgebase.keys())+1,VOCAB_SIZE,device=device)\n",
    "for i,tag in enumerate(knowledgebase.keys()):\n",
    "    idx = [generic_word2id[word] for word in knowledgebase[tag]]\n",
    "    mask[i,idx] = 1\n",
    "mask[-1] = 1\n",
    "mask[mask==0] = -10000\n",
    "lang_model = LM(vocab_size=VOCAB_SIZE, \n",
    "                hidden_size=HIDDEN_SIZE,\n",
    "                token_embedding_size=EMBEDDING_SIZE,\n",
    "                tag_embedding_size=TAG_EMBEDDING_SIZE,\n",
    "                tags = knowledgebase.keys(), \n",
    "                mask = mask,\n",
    "               device = device).to(device)\n",
    "criterion = nn.NLLLoss(ignore_index=2)\n",
    "optimizer = optim.Adam(lang_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,val_loader,criterion,device):\n",
    "    model.eval()\n",
    "    token_acc = 0\n",
    "    total_tokens = 0\n",
    "    sent_acc = 0\n",
    "    total_sent = 0\n",
    "    val_nll = 0\n",
    "    for batch,(input_seq,target_seq,target_labels) in enumerate(val_loader):\n",
    "        input_seq = input_seq.to(device)\n",
    "        target_labels = target_labels.to(device)\n",
    "        target_seq = target_seq.to(device)\n",
    "        pred_labels,pred_words = model(input_seq)\n",
    "        batch_size,sent_len = input_seq.shape[0],input_seq.shape[1]\n",
    "        for i in range(batch_size):\n",
    "            word_correct = 0\n",
    "            total_sent+=1\n",
    "            sent_len = 0\n",
    "            for j in range(input_seq.shape[1]-1):\n",
    "                if target_labels[i,j]!=37:\n",
    "                    #print(target_labels[i,j])\n",
    "                    sent_len+=1\n",
    "                    if pred_labels[i,j].long()==target_labels[i,j]:\n",
    "                        word_correct+=1\n",
    "            total_tokens+=sent_len\n",
    "            token_acc+=word_correct\n",
    "            if sent_len==word_correct:\n",
    "                sent_acc+=1\n",
    "        loss = 0\n",
    "        for i in range(input_seq.shape[1]):\n",
    "            loss+= criterion(pred_words[:,i,:],target_seq[:,i])\n",
    "        val_nll+=loss.item()\n",
    "    token_acc = float(token_acc)/float(total_tokens)\n",
    "    sent_acc = float(sent_acc)/float(total_sent)\n",
    "    val_nll/=total_tokens\n",
    "    return token_acc,sent_acc,val_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,val_loader,optimizer,criterion,device,num_epochs=10):\n",
    "    c_point = 238*2\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        total_tokens = 0\n",
    "        for batch,(input_seq,target_seq) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_seq = model(input_seq)\n",
    "            loss = 0\n",
    "            for i in range(input_seq.shape[1]):\n",
    "                loss+= criterion(pred_seq[:,i,:],target_seq[:,i])\n",
    "            #print(loss)\n",
    "            train_loss+=loss.item()\n",
    "            total_tokens+=(input_seq.shape[1]*input_seq.shape[0])\n",
    "            loss/=(input_seq.shape[1]*input_seq.shape[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch+1)%c_point==0:\n",
    "                token_acc,sent_acc, val_loss = evaluate(model,val_loader,criterion,device)\n",
    "                print('epoch: {} | step: {}/{} | train loss: {} | token acc: {} | sent acc: {} | val loss: {}'.format(epoch+1,\n",
    "                                                                                                                      (batch+1)//c_point,\n",
    "                                                                                                                      len(train_loader)//c_point,\n",
    "                                                                                                                      round(train_loss/total_tokens,3),\n",
    "                                                                                                                      round(token_acc,3),\n",
    "                                                                                                                      round(sent_acc,3),\n",
    "                                                                                                                      round(val_loss,3)))\n",
    "                train_loss = 0\n",
    "                total_tokens = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | step: 1/5 | train loss: 0.319 | token acc: 0.072 | sent acc: 0.0 | val loss: 0.522\n",
      "epoch: 1 | step: 2/5 | train loss: 0.304 | token acc: 0.001 | sent acc: 0.0 | val loss: 0.417\n",
      "epoch: 1 | step: 3/5 | train loss: 0.294 | token acc: 0.008 | sent acc: 0.0 | val loss: 0.36\n",
      "epoch: 1 | step: 4/5 | train loss: 0.284 | token acc: 0.012 | sent acc: 0.0 | val loss: 0.309\n"
     ]
    }
   ],
   "source": [
    "train(lang_model,train_loader,val_loader,optimizer,criterion,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [3, 8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2],[3,4]])*torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
